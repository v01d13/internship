{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50a165fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aafef1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Import the dataset\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04b9bc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'Outcome']\n",
    "y = df.loc[:, df.columns == 'Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3661bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "936c9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scale the X train and test before passing it into the neural network\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "479b6c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Neural network with Dense layers\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units = 3, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(units = 5, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(units = 2, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(units=1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'SGD', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "136c42aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "18/18 [==============================] - 1s 19ms/step - loss: 0.6072 - accuracy: 0.6727 - val_loss: 0.5734 - val_accuracy: 0.6927\n",
      "Epoch 2/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6122 - accuracy: 0.6351 - val_loss: 0.5641 - val_accuracy: 0.6875\n",
      "Epoch 3/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.6716 - val_loss: 0.5558 - val_accuracy: 0.6771\n",
      "Epoch 4/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.6437 - val_loss: 0.5484 - val_accuracy: 0.6719\n",
      "Epoch 5/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.6199 - val_loss: 0.5415 - val_accuracy: 0.6719\n",
      "Epoch 6/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.6282 - val_loss: 0.5354 - val_accuracy: 0.6719\n",
      "Epoch 7/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.6369 - val_loss: 0.5299 - val_accuracy: 0.6719\n",
      "Epoch 8/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5760 - accuracy: 0.6630 - val_loss: 0.5250 - val_accuracy: 0.6719\n",
      "Epoch 9/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.6597 - val_loss: 0.5207 - val_accuracy: 0.6719\n",
      "Epoch 10/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5605 - accuracy: 0.6481 - val_loss: 0.5167 - val_accuracy: 0.6719\n",
      "Epoch 11/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5449 - accuracy: 0.6609 - val_loss: 0.5132 - val_accuracy: 0.6719\n",
      "Epoch 12/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5583 - accuracy: 0.6501 - val_loss: 0.5101 - val_accuracy: 0.6719\n",
      "Epoch 13/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.6542 - val_loss: 0.5068 - val_accuracy: 0.6719\n",
      "Epoch 14/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.6670 - val_loss: 0.5037 - val_accuracy: 0.6823\n",
      "Epoch 15/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.6676 - val_loss: 0.5009 - val_accuracy: 0.6875\n",
      "Epoch 16/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.6754 - val_loss: 0.4985 - val_accuracy: 0.6771\n",
      "Epoch 17/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.6681 - val_loss: 0.4962 - val_accuracy: 0.6875\n",
      "Epoch 18/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.6448 - val_loss: 0.4940 - val_accuracy: 0.6823\n",
      "Epoch 19/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.6316 - val_loss: 0.4921 - val_accuracy: 0.6823\n",
      "Epoch 20/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5341 - accuracy: 0.6919 - val_loss: 0.4903 - val_accuracy: 0.6823\n",
      "Epoch 21/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.6768 - val_loss: 0.4885 - val_accuracy: 0.6823\n",
      "Epoch 22/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7004 - val_loss: 0.4868 - val_accuracy: 0.7135\n",
      "Epoch 23/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.7137 - val_loss: 0.4853 - val_accuracy: 0.7135\n",
      "Epoch 24/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5345 - accuracy: 0.7447 - val_loss: 0.4839 - val_accuracy: 0.7083\n",
      "Epoch 25/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.7152 - val_loss: 0.4825 - val_accuracy: 0.7083\n",
      "Epoch 26/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7547 - val_loss: 0.4814 - val_accuracy: 0.7188\n",
      "Epoch 27/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5505 - accuracy: 0.7121 - val_loss: 0.4802 - val_accuracy: 0.7188\n",
      "Epoch 28/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7213 - val_loss: 0.4791 - val_accuracy: 0.7188\n",
      "Epoch 29/250\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5343 - accuracy: 0.7178 - val_loss: 0.4782 - val_accuracy: 0.7240\n",
      "Epoch 30/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5319 - accuracy: 0.7465 - val_loss: 0.4772 - val_accuracy: 0.7292\n",
      "Epoch 31/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.7198 - val_loss: 0.4764 - val_accuracy: 0.7292\n",
      "Epoch 32/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7355 - val_loss: 0.4757 - val_accuracy: 0.7292\n",
      "Epoch 33/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7328 - val_loss: 0.4751 - val_accuracy: 0.7292\n",
      "Epoch 34/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7154 - val_loss: 0.4746 - val_accuracy: 0.7292\n",
      "Epoch 35/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7359 - val_loss: 0.4741 - val_accuracy: 0.7292\n",
      "Epoch 36/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7250 - val_loss: 0.4735 - val_accuracy: 0.7240\n",
      "Epoch 37/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7399 - val_loss: 0.4729 - val_accuracy: 0.7240\n",
      "Epoch 38/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7418 - val_loss: 0.4724 - val_accuracy: 0.7188\n",
      "Epoch 39/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7327 - val_loss: 0.4718 - val_accuracy: 0.7188\n",
      "Epoch 40/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7481 - val_loss: 0.4714 - val_accuracy: 0.7135\n",
      "Epoch 41/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7146 - val_loss: 0.4710 - val_accuracy: 0.7135\n",
      "Epoch 42/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.7337 - val_loss: 0.4705 - val_accuracy: 0.7135\n",
      "Epoch 43/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7377 - val_loss: 0.4701 - val_accuracy: 0.7135\n",
      "Epoch 44/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7300 - val_loss: 0.4698 - val_accuracy: 0.7135\n",
      "Epoch 45/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7308 - val_loss: 0.4695 - val_accuracy: 0.7135\n",
      "Epoch 46/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5140 - accuracy: 0.7407 - val_loss: 0.4692 - val_accuracy: 0.7135\n",
      "Epoch 47/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5130 - accuracy: 0.7378 - val_loss: 0.4689 - val_accuracy: 0.7135\n",
      "Epoch 48/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7101 - val_loss: 0.4686 - val_accuracy: 0.7135\n",
      "Epoch 49/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.7273 - val_loss: 0.4684 - val_accuracy: 0.7188\n",
      "Epoch 50/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7627 - val_loss: 0.4682 - val_accuracy: 0.7240\n",
      "Epoch 51/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7350 - val_loss: 0.4680 - val_accuracy: 0.7240\n",
      "Epoch 52/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7390 - val_loss: 0.4678 - val_accuracy: 0.7292\n",
      "Epoch 53/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7379 - val_loss: 0.4676 - val_accuracy: 0.7396\n",
      "Epoch 54/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7458 - val_loss: 0.4674 - val_accuracy: 0.7396\n",
      "Epoch 55/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7611 - val_loss: 0.4672 - val_accuracy: 0.7396\n",
      "Epoch 56/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7601 - val_loss: 0.4670 - val_accuracy: 0.7344\n",
      "Epoch 57/250\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4926 - accuracy: 0.7430 - val_loss: 0.4668 - val_accuracy: 0.7344\n",
      "Epoch 58/250\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5255 - accuracy: 0.7300 - val_loss: 0.4667 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5030 - accuracy: 0.7417 - val_loss: 0.4665 - val_accuracy: 0.7396\n",
      "Epoch 60/250\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5012 - accuracy: 0.7642 - val_loss: 0.4664 - val_accuracy: 0.7396\n",
      "Epoch 61/250\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5259 - accuracy: 0.7127 - val_loss: 0.4662 - val_accuracy: 0.7448\n",
      "Epoch 62/250\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5080 - accuracy: 0.7396 - val_loss: 0.4661 - val_accuracy: 0.7500\n",
      "Epoch 63/250\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5030 - accuracy: 0.7599 - val_loss: 0.4660 - val_accuracy: 0.7396\n",
      "Epoch 64/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7593 - val_loss: 0.4659 - val_accuracy: 0.7344\n",
      "Epoch 65/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.7491 - val_loss: 0.4659 - val_accuracy: 0.7344\n",
      "Epoch 66/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.7635 - val_loss: 0.4659 - val_accuracy: 0.7448\n",
      "Epoch 67/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7660 - val_loss: 0.4658 - val_accuracy: 0.7344\n",
      "Epoch 68/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7607 - val_loss: 0.4657 - val_accuracy: 0.7344\n",
      "Epoch 69/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.7770 - val_loss: 0.4656 - val_accuracy: 0.7396\n",
      "Epoch 70/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.7609 - val_loss: 0.4655 - val_accuracy: 0.7344\n",
      "Epoch 71/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7718 - val_loss: 0.4654 - val_accuracy: 0.7344\n",
      "Epoch 72/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4877 - accuracy: 0.7835 - val_loss: 0.4653 - val_accuracy: 0.7344\n",
      "Epoch 73/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7629 - val_loss: 0.4653 - val_accuracy: 0.7344\n",
      "Epoch 74/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7752 - val_loss: 0.4653 - val_accuracy: 0.7344\n",
      "Epoch 75/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7783 - val_loss: 0.4653 - val_accuracy: 0.7344\n",
      "Epoch 76/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7731 - val_loss: 0.4652 - val_accuracy: 0.7344\n",
      "Epoch 77/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7499 - val_loss: 0.4651 - val_accuracy: 0.7344\n",
      "Epoch 78/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7502 - val_loss: 0.4650 - val_accuracy: 0.7344\n",
      "Epoch 79/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7681 - val_loss: 0.4650 - val_accuracy: 0.7344\n",
      "Epoch 80/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7903 - val_loss: 0.4648 - val_accuracy: 0.7292\n",
      "Epoch 81/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7539 - val_loss: 0.4648 - val_accuracy: 0.7292\n",
      "Epoch 82/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7518 - val_loss: 0.4647 - val_accuracy: 0.7292\n",
      "Epoch 83/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7717 - val_loss: 0.4646 - val_accuracy: 0.7292\n",
      "Epoch 84/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.7660 - val_loss: 0.4645 - val_accuracy: 0.7240\n",
      "Epoch 85/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7645 - val_loss: 0.4644 - val_accuracy: 0.7344\n",
      "Epoch 86/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7401 - val_loss: 0.4643 - val_accuracy: 0.7240\n",
      "Epoch 87/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7603 - val_loss: 0.4642 - val_accuracy: 0.7240\n",
      "Epoch 88/250\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4795 - accuracy: 0.7792 - val_loss: 0.4642 - val_accuracy: 0.7240\n",
      "Epoch 89/250\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4855 - accuracy: 0.7647 - val_loss: 0.4642 - val_accuracy: 0.7240\n",
      "Epoch 90/250\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5090 - accuracy: 0.7673 - val_loss: 0.4642 - val_accuracy: 0.7240\n",
      "Epoch 91/250\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4992 - accuracy: 0.7480 - val_loss: 0.4641 - val_accuracy: 0.7240\n",
      "Epoch 92/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7726 - val_loss: 0.4641 - val_accuracy: 0.7292\n",
      "Epoch 93/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.7798 - val_loss: 0.4641 - val_accuracy: 0.7292\n",
      "Epoch 94/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7576 - val_loss: 0.4640 - val_accuracy: 0.7344\n",
      "Epoch 95/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7454 - val_loss: 0.4639 - val_accuracy: 0.7344\n",
      "Epoch 96/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.7668 - val_loss: 0.4640 - val_accuracy: 0.7344\n",
      "Epoch 97/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.7606 - val_loss: 0.4639 - val_accuracy: 0.7396\n",
      "Epoch 98/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7851 - val_loss: 0.4639 - val_accuracy: 0.7396\n",
      "Epoch 99/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7745 - val_loss: 0.4639 - val_accuracy: 0.7396\n",
      "Epoch 100/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7548 - val_loss: 0.4639 - val_accuracy: 0.7396\n",
      "Epoch 101/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7722 - val_loss: 0.4639 - val_accuracy: 0.7344\n",
      "Epoch 102/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7498 - val_loss: 0.4639 - val_accuracy: 0.7344\n",
      "Epoch 103/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7503 - val_loss: 0.4640 - val_accuracy: 0.7344\n",
      "Epoch 104/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7767 - val_loss: 0.4640 - val_accuracy: 0.7396\n",
      "Epoch 105/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7870 - val_loss: 0.4640 - val_accuracy: 0.7448\n",
      "Epoch 106/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7938 - val_loss: 0.4641 - val_accuracy: 0.7500\n",
      "Epoch 107/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7480 - val_loss: 0.4642 - val_accuracy: 0.7500\n",
      "Epoch 108/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7611 - val_loss: 0.4643 - val_accuracy: 0.7500\n",
      "Epoch 109/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7461 - val_loss: 0.4644 - val_accuracy: 0.7500\n",
      "Epoch 110/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7563 - val_loss: 0.4644 - val_accuracy: 0.7500\n",
      "Epoch 111/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7361 - val_loss: 0.4646 - val_accuracy: 0.7500\n",
      "Epoch 112/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.8064 - val_loss: 0.4647 - val_accuracy: 0.7500\n",
      "Epoch 113/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.7749 - val_loss: 0.4649 - val_accuracy: 0.7500\n",
      "Epoch 114/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7495 - val_loss: 0.4651 - val_accuracy: 0.7500\n",
      "Epoch 115/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7773 - val_loss: 0.4652 - val_accuracy: 0.7500\n",
      "Epoch 116/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7688 - val_loss: 0.4653 - val_accuracy: 0.7500\n",
      "Epoch 117/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7334 - val_loss: 0.4654 - val_accuracy: 0.7500\n",
      "Epoch 118/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7610 - val_loss: 0.4656 - val_accuracy: 0.7500\n",
      "Epoch 119/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7968 - val_loss: 0.4657 - val_accuracy: 0.7500\n",
      "Epoch 120/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.7379 - val_loss: 0.4658 - val_accuracy: 0.7500\n",
      "Epoch 121/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7697 - val_loss: 0.4659 - val_accuracy: 0.7500\n",
      "Epoch 122/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7553 - val_loss: 0.4660 - val_accuracy: 0.7500\n",
      "Epoch 123/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7479 - val_loss: 0.4661 - val_accuracy: 0.7448\n",
      "Epoch 124/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7391 - val_loss: 0.4662 - val_accuracy: 0.7500\n",
      "Epoch 125/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7600 - val_loss: 0.4663 - val_accuracy: 0.7500\n",
      "Epoch 126/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7675 - val_loss: 0.4664 - val_accuracy: 0.7500\n",
      "Epoch 127/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7376 - val_loss: 0.4665 - val_accuracy: 0.7500\n",
      "Epoch 128/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7489 - val_loss: 0.4667 - val_accuracy: 0.7500\n",
      "Epoch 129/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7572 - val_loss: 0.4670 - val_accuracy: 0.7500\n",
      "Epoch 130/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7674 - val_loss: 0.4671 - val_accuracy: 0.7500\n",
      "Epoch 131/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7894 - val_loss: 0.4672 - val_accuracy: 0.7448\n",
      "Epoch 132/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7557 - val_loss: 0.4674 - val_accuracy: 0.7448\n",
      "Epoch 133/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7540 - val_loss: 0.4676 - val_accuracy: 0.7448\n",
      "Epoch 134/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.7759 - val_loss: 0.4677 - val_accuracy: 0.7396\n",
      "Epoch 135/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7441 - val_loss: 0.4678 - val_accuracy: 0.7396\n",
      "Epoch 136/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7611 - val_loss: 0.4680 - val_accuracy: 0.7448\n",
      "Epoch 137/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.7515 - val_loss: 0.4681 - val_accuracy: 0.7448\n",
      "Epoch 138/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7713 - val_loss: 0.4683 - val_accuracy: 0.7448\n",
      "Epoch 139/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7629 - val_loss: 0.4684 - val_accuracy: 0.7448\n",
      "Epoch 140/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7628 - val_loss: 0.4685 - val_accuracy: 0.7448\n",
      "Epoch 141/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7512 - val_loss: 0.4686 - val_accuracy: 0.7448\n",
      "Epoch 142/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7473 - val_loss: 0.4687 - val_accuracy: 0.7448\n",
      "Epoch 143/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7853 - val_loss: 0.4688 - val_accuracy: 0.7448\n",
      "Epoch 144/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7345 - val_loss: 0.4689 - val_accuracy: 0.7448\n",
      "Epoch 145/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.7559 - val_loss: 0.4690 - val_accuracy: 0.7448\n",
      "Epoch 146/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7558 - val_loss: 0.4690 - val_accuracy: 0.7448\n",
      "Epoch 147/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7743 - val_loss: 0.4691 - val_accuracy: 0.7448\n",
      "Epoch 148/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7523 - val_loss: 0.4693 - val_accuracy: 0.7448\n",
      "Epoch 149/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7459 - val_loss: 0.4693 - val_accuracy: 0.7500\n",
      "Epoch 150/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7765 - val_loss: 0.4693 - val_accuracy: 0.7500\n",
      "Epoch 151/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7515 - val_loss: 0.4694 - val_accuracy: 0.7500\n",
      "Epoch 152/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7597 - val_loss: 0.4693 - val_accuracy: 0.7500\n",
      "Epoch 153/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.7792 - val_loss: 0.4693 - val_accuracy: 0.7500\n",
      "Epoch 154/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7759 - val_loss: 0.4694 - val_accuracy: 0.7500\n",
      "Epoch 155/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7542 - val_loss: 0.4693 - val_accuracy: 0.7500\n",
      "Epoch 156/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7633 - val_loss: 0.4694 - val_accuracy: 0.7500\n",
      "Epoch 157/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7672 - val_loss: 0.4695 - val_accuracy: 0.7500\n",
      "Epoch 158/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7648 - val_loss: 0.4695 - val_accuracy: 0.7500\n",
      "Epoch 159/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7787 - val_loss: 0.4695 - val_accuracy: 0.7500\n",
      "Epoch 160/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7530 - val_loss: 0.4696 - val_accuracy: 0.7500\n",
      "Epoch 161/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7616 - val_loss: 0.4696 - val_accuracy: 0.7500\n",
      "Epoch 162/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7720 - val_loss: 0.4696 - val_accuracy: 0.7500\n",
      "Epoch 163/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7636 - val_loss: 0.4696 - val_accuracy: 0.7500\n",
      "Epoch 164/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7601 - val_loss: 0.4695 - val_accuracy: 0.7500\n",
      "Epoch 165/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7756 - val_loss: 0.4695 - val_accuracy: 0.7500\n",
      "Epoch 166/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7801 - val_loss: 0.4694 - val_accuracy: 0.7500\n",
      "Epoch 167/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7764 - val_loss: 0.4693 - val_accuracy: 0.7500\n",
      "Epoch 168/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7646 - val_loss: 0.4693 - val_accuracy: 0.7500\n",
      "Epoch 169/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7647 - val_loss: 0.4692 - val_accuracy: 0.7552\n",
      "Epoch 170/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.7905 - val_loss: 0.4691 - val_accuracy: 0.7552\n",
      "Epoch 171/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.7527 - val_loss: 0.4692 - val_accuracy: 0.7552\n",
      "Epoch 172/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7441 - val_loss: 0.4691 - val_accuracy: 0.7552\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7615 - val_loss: 0.4692 - val_accuracy: 0.7552\n",
      "Epoch 174/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7799 - val_loss: 0.4692 - val_accuracy: 0.7552\n",
      "Epoch 175/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7766 - val_loss: 0.4691 - val_accuracy: 0.7552\n",
      "Epoch 176/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7621 - val_loss: 0.4691 - val_accuracy: 0.7552\n",
      "Epoch 177/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7941 - val_loss: 0.4691 - val_accuracy: 0.7500\n",
      "Epoch 178/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7862 - val_loss: 0.4692 - val_accuracy: 0.7500\n",
      "Epoch 179/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7962 - val_loss: 0.4692 - val_accuracy: 0.7500\n",
      "Epoch 180/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7899 - val_loss: 0.4691 - val_accuracy: 0.7500\n",
      "Epoch 181/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.7626 - val_loss: 0.4690 - val_accuracy: 0.7500\n",
      "Epoch 182/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7776 - val_loss: 0.4690 - val_accuracy: 0.7500\n",
      "Epoch 183/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.8027 - val_loss: 0.4690 - val_accuracy: 0.7500\n",
      "Epoch 184/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7877 - val_loss: 0.4691 - val_accuracy: 0.7500\n",
      "Epoch 185/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.8001 - val_loss: 0.4691 - val_accuracy: 0.7500\n",
      "Epoch 186/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7754 - val_loss: 0.4690 - val_accuracy: 0.7500\n",
      "Epoch 187/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7696 - val_loss: 0.4690 - val_accuracy: 0.7552\n",
      "Epoch 188/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7524 - val_loss: 0.4687 - val_accuracy: 0.7552\n",
      "Epoch 189/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7559 - val_loss: 0.4684 - val_accuracy: 0.7552\n",
      "Epoch 190/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7816 - val_loss: 0.4682 - val_accuracy: 0.7552\n",
      "Epoch 191/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7834 - val_loss: 0.4680 - val_accuracy: 0.7552\n",
      "Epoch 192/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7843 - val_loss: 0.4677 - val_accuracy: 0.7552\n",
      "Epoch 193/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7893 - val_loss: 0.4675 - val_accuracy: 0.7552\n",
      "Epoch 194/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7676 - val_loss: 0.4673 - val_accuracy: 0.7552\n",
      "Epoch 195/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7660 - val_loss: 0.4673 - val_accuracy: 0.7552\n",
      "Epoch 196/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7888 - val_loss: 0.4671 - val_accuracy: 0.7552\n",
      "Epoch 197/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.7672 - val_loss: 0.4670 - val_accuracy: 0.7552\n",
      "Epoch 198/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7649 - val_loss: 0.4668 - val_accuracy: 0.7552\n",
      "Epoch 199/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7740 - val_loss: 0.4666 - val_accuracy: 0.7552\n",
      "Epoch 200/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7838 - val_loss: 0.4665 - val_accuracy: 0.7552\n",
      "Epoch 201/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7541 - val_loss: 0.4664 - val_accuracy: 0.7552\n",
      "Epoch 202/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.7745 - val_loss: 0.4663 - val_accuracy: 0.7552\n",
      "Epoch 203/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7799 - val_loss: 0.4662 - val_accuracy: 0.7552\n",
      "Epoch 204/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7889 - val_loss: 0.4662 - val_accuracy: 0.7552\n",
      "Epoch 205/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.7558 - val_loss: 0.4661 - val_accuracy: 0.7552\n",
      "Epoch 206/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7516 - val_loss: 0.4661 - val_accuracy: 0.7552\n",
      "Epoch 207/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7652 - val_loss: 0.4662 - val_accuracy: 0.7552\n",
      "Epoch 208/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7574 - val_loss: 0.4662 - val_accuracy: 0.7552\n",
      "Epoch 209/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.8009 - val_loss: 0.4663 - val_accuracy: 0.7552\n",
      "Epoch 210/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7657 - val_loss: 0.4664 - val_accuracy: 0.7552\n",
      "Epoch 211/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7659 - val_loss: 0.4665 - val_accuracy: 0.7552\n",
      "Epoch 212/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7947 - val_loss: 0.4664 - val_accuracy: 0.7552\n",
      "Epoch 213/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.8031 - val_loss: 0.4667 - val_accuracy: 0.7552\n",
      "Epoch 214/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7885 - val_loss: 0.4667 - val_accuracy: 0.7552\n",
      "Epoch 215/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.8151 - val_loss: 0.4667 - val_accuracy: 0.7552\n",
      "Epoch 216/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.7811 - val_loss: 0.4668 - val_accuracy: 0.7552\n",
      "Epoch 217/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7930 - val_loss: 0.4670 - val_accuracy: 0.7552\n",
      "Epoch 218/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7624 - val_loss: 0.4671 - val_accuracy: 0.7552\n",
      "Epoch 219/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.8008 - val_loss: 0.4671 - val_accuracy: 0.7552\n",
      "Epoch 220/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.8103 - val_loss: 0.4672 - val_accuracy: 0.7552\n",
      "Epoch 221/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.8171 - val_loss: 0.4674 - val_accuracy: 0.7552\n",
      "Epoch 222/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7728 - val_loss: 0.4674 - val_accuracy: 0.7552\n",
      "Epoch 223/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.8000 - val_loss: 0.4676 - val_accuracy: 0.7552\n",
      "Epoch 224/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7822 - val_loss: 0.4678 - val_accuracy: 0.7552\n",
      "Epoch 225/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7689 - val_loss: 0.4679 - val_accuracy: 0.7552\n",
      "Epoch 226/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.8015 - val_loss: 0.4681 - val_accuracy: 0.7500\n",
      "Epoch 227/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7912 - val_loss: 0.4683 - val_accuracy: 0.7500\n",
      "Epoch 228/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7887 - val_loss: 0.4686 - val_accuracy: 0.7500\n",
      "Epoch 229/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7818 - val_loss: 0.4688 - val_accuracy: 0.7500\n",
      "Epoch 230/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7832 - val_loss: 0.4691 - val_accuracy: 0.7500\n",
      "Epoch 231/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7897 - val_loss: 0.4694 - val_accuracy: 0.7500\n",
      "Epoch 232/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7785 - val_loss: 0.4697 - val_accuracy: 0.7500\n",
      "Epoch 233/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7747 - val_loss: 0.4700 - val_accuracy: 0.7500\n",
      "Epoch 234/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7784 - val_loss: 0.4701 - val_accuracy: 0.7500\n",
      "Epoch 235/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.7714 - val_loss: 0.4703 - val_accuracy: 0.7500\n",
      "Epoch 236/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.8039 - val_loss: 0.4705 - val_accuracy: 0.7552\n",
      "Epoch 237/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7855 - val_loss: 0.4706 - val_accuracy: 0.7552\n",
      "Epoch 238/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7944 - val_loss: 0.4708 - val_accuracy: 0.7552\n",
      "Epoch 239/250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7894 - val_loss: 0.4708 - val_accuracy: 0.7552\n",
      "Epoch 240/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7926 - val_loss: 0.4710 - val_accuracy: 0.7552\n",
      "Epoch 241/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7755 - val_loss: 0.4711 - val_accuracy: 0.7552\n",
      "Epoch 242/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4867 - accuracy: 0.7783 - val_loss: 0.4713 - val_accuracy: 0.7552\n",
      "Epoch 243/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7956 - val_loss: 0.4714 - val_accuracy: 0.7552\n",
      "Epoch 244/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8076 - val_loss: 0.4716 - val_accuracy: 0.7552\n",
      "Epoch 245/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7641 - val_loss: 0.4717 - val_accuracy: 0.7552\n",
      "Epoch 246/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7885 - val_loss: 0.4718 - val_accuracy: 0.7552\n",
      "Epoch 247/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.7752 - val_loss: 0.4719 - val_accuracy: 0.7552\n",
      "Epoch 248/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7728 - val_loss: 0.4721 - val_accuracy: 0.7552\n",
      "Epoch 249/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4924 - accuracy: 0.7707 - val_loss: 0.4722 - val_accuracy: 0.7552\n",
      "Epoch 250/250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7777 - val_loss: 0.4722 - val_accuracy: 0.7552\n"
     ]
    }
   ],
   "source": [
    "ann = model.fit(X_train, y_train, epochs = 250, validation_data = (X_test, y_test),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "698dcbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Plot the loss of the training and validation set\n",
    "training_loss = ann.history['loss']\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "test_loss = ann.history['val_loss']\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
